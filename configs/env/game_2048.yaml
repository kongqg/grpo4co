defaults:
  - grpo_config
  - _self_
env:
  registered_version: Game2048-v1
  name: "game_2048"
  network:
    num_channels: 32
    policy_layers: [ 128, 128 ]
    value_layers: [ 256, 256 ]
  a2c:
    normalize_advantage: False
    discount_factor: 0.99
    bootstrapping_factor: 0.95
    l_pg: 1.0
    l_td: 1.0
    l_en: 0.01
    learning_rate: 2e-4
  training:
    num_epochs: 100
    num_learner_steps_per_epoch: 600
    n_steps: 50
    total_batch_size: 32
    steps_per_epoch: 600 * 50 * 32 # grpo 总的步数
    total_steps: 600 * 50 * 32 * 100
  evaluation:
    eval_total_batch_size: 128
    greedy_eval_total_batch_size: 128
seed: 0

logger:
  type: "tensorboard"  # 指定日志记录器的类型为 tensorboard
  project: "grpo4co"
  name: "a2c_2048"
  save_checkpoint: true
#agent: "grpo"
