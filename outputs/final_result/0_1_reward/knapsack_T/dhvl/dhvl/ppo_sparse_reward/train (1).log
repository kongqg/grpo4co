[2026-01-20 23:36:44,016][root][INFO] - agent: ppo
grpo:
  supervision_mode: outcome
  clip_eps: 0.1
  normalize_adv: true
  kl_coef: 0.005
  percentile_p: -1
  mean_reward_method: true
  reward_mode: sparse
ppo:
  lambda: 0.95
  normalize_adv: true
  clip_eps: 0.1
dhvl:
  bootstrapping_factor: 1.95
  policy_delay: 2
  update_epochs: 4
  tau: 0.5
  clip_eps: 0.1
  minibatch_size: 64
  target_kl: 0.2
  tar_tau: 0.01
env:
  name: knapsack
  registered_version: Knapsack-v1
  network:
    transformer_num_blocks: 6
    transformer_num_heads: 8
    transformer_key_size: 16
    transformer_mlp_units:
    - 512
  training:
    num_epochs: 100
    num_learner_steps_per_epoch: 50
    n_steps: 20
    total_batch_size: 64
  evaluation:
    eval_total_batch_size: 10000
    greedy_eval_total_batch_size: 10000
  a2c:
    normalize_advantage: false
    discount_factor: 1.0
    bootstrapping_factor: 0.95
    l_pg: 1.0
    l_td: 1.0
    l_en: 0.01
    learning_rate: 0.0001
seed: 0
logger:
  type: tensorboard
  project: grpo4co
  name: knapsack
  save_checkpoint: true

[2026-01-20 23:36:44,016][root][INFO] - {'devices': [CudaDevice(id=0)]}
[2026-01-20 23:36:44,294][root][INFO] - knapsack
[2026-01-20 23:36:54,710][root][INFO] - Starting logger.
